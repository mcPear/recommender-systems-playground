{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "from scipy import stats\n",
    "from ast import literal_eval\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hybrid(object):\n",
    "    \n",
    "    def __init__ (self,user_id,ratings):\n",
    "        \n",
    "        self.user_id = user_id\n",
    "        self.md = pd.read_csv('dataset/processed/FinalData.csv')\n",
    "        self.ratings = ratings\n",
    "        self.res=None\n",
    "        print(ratings)\n",
    "        print(ratings[(ratings['user_id'] == user_id)][['user_id','book_id', 'rating']])\n",
    "        print('STARTING POPULARITY')\n",
    "        self.popularity_rating = self.popularity(self.md)\n",
    "        print('STARTING CONTENT')\n",
    "        self.content_rating = self.content_based(self.md,self.ratings,self.user_id)\n",
    "        print('STARTING COLABORATIVE')\n",
    "        self.collaborative_rating = self.collaborative(self.ratings, self.user_id)\n",
    "        print('STARTING HYBRID')\n",
    "        self.final_hybrid(self.md, self.popularity_rating , self.collaborative_rating, self.content_rating, self.user_id)\n",
    "        \n",
    "        \n",
    "    #Popularity#\n",
    "\n",
    "    def popularity(self,md):\n",
    "\n",
    "\n",
    "        fd = pd.read_csv('dataset/processed/AverageRatings.csv')\n",
    "        fd1 = pd.read_csv('dataset/processed/RatingsCount.csv')\n",
    "\t\n",
    "        fd[fd['rating'].notnull()]['rating'] = fd[fd['rating'].notnull()]['rating'].astype('float')\n",
    "        vote_averages= fd[fd['rating'].notnull()]['rating'] \n",
    "        C = vote_averages.mean()\n",
    "\n",
    "\n",
    "        fd1[fd1['rating'].notnull()]['rating'] = fd1[fd1['rating'].notnull()]['rating'].astype('float')\n",
    "        vote_counts = fd1[fd1['rating'].notnull()]['rating']\n",
    "        m = len(vote_counts)\n",
    "\n",
    "        md['ratings_count'] = fd1['rating']\n",
    "        md['average_rating'] = fd['rating']\n",
    "\n",
    "        qualified = md[(md['ratings_count'].notnull())][['book_id','title', 'authors', 'ratings_count', 'average_rating']]\n",
    "\n",
    "        qualified['ratings_count'] = qualified['ratings_count'].astype('float')\n",
    "\n",
    "        qualified['average_rating'] = qualified['average_rating'].astype('float')\n",
    "\n",
    "        qualified.shape\n",
    "\n",
    "        def weighted_rating(x):\n",
    "            v = x['ratings_count']\n",
    "            R = x['average_rating']\n",
    "            return (v/(v+m) * R) + (m/(m+v) * C)\n",
    "\n",
    "        qualified['popularity_rating'] = qualified.apply(weighted_rating, axis=1)\n",
    "        pop = qualified[['book_id','popularity_rating']]\n",
    "        print(qualified.shape)\n",
    "        print(pop.shape)\n",
    "\n",
    "        return pop\n",
    "    ### Collaborative ##\n",
    "\n",
    "    def collaborative(self,ratings,user_id):\n",
    "\n",
    "        reader = Reader()\n",
    "        #ratings.head()\n",
    "\n",
    "        temp_ratings = ratings\n",
    "\n",
    "\n",
    "\n",
    "        data = Dataset.load_from_df(temp_ratings[['user_id', 'book_id', 'rating']], reader)\n",
    "#         data.split(n_folds=2)\n",
    "\n",
    "        ## Training the data ##\n",
    "        svd = SVD()\n",
    "#         evaluate(svd, data, measures=['RMSE', 'MAE'])\n",
    "        cross_validate(svd, data, measures=['RMSE', 'MAE'])\n",
    "\n",
    "        trainset = data.build_full_trainset()\n",
    "\n",
    "        algo = SVD()\n",
    "        algo.fit(trainset)\n",
    "\n",
    "        #svd.train(trainset)\n",
    "        ## Testing the data ##\n",
    "\n",
    "        from collections import defaultdict\n",
    "        testset = trainset.build_anti_testset()\n",
    "        predictions = algo.test(testset)\n",
    "\n",
    "        count = 0\n",
    "     \n",
    "        for uid, iid, true_r, est, _ in predictions:\n",
    "\n",
    "             if uid == user_id:\n",
    "                count = count+1\n",
    "                temp_ratings.loc[len(temp_ratings)+1]= [uid,iid,est]\n",
    "\n",
    "        #print(\"count\\n\")\n",
    "        #print(count)\n",
    "        #print(\"\\n--------here-------\\n\")\t\n",
    "        #print(temp_ratings)\n",
    "\n",
    "        cb = temp_ratings[(temp_ratings['user_id'] == user_id)][['book_id', 'rating']]\n",
    "        #print(\"\\n--------here-------\\n\")\n",
    "        #print(cb)\n",
    "        \n",
    "        cb = temp_ratings[(temp_ratings['user_id'] == user_id)][['book_id', 'rating']]\n",
    "\n",
    "        return(cb)\n",
    "\n",
    "\n",
    "    ##### CONTENT ######\n",
    "\n",
    "    def content_based(self,md,ratings,user_id):       \n",
    "\n",
    "        md['book_id'] = md['book_id'].astype('str')\n",
    "        md['year'] = md['year'].astype('str')\n",
    "        ratings['book_id'] = ratings['book_id'].astype('str')\n",
    "        ratings['user_id'] = ratings['user_id'].astype('int')\n",
    "        ratings['rating'] = ratings['rating'].astype('int')\n",
    "        md['authors'] = md['authors'].str.replace(' ','')\n",
    "        md['authors'] = md['authors'].str.lower()\n",
    "#         md['authors'] = md['authors'].str.replace('.',' ')\n",
    "#         md['authors'] = md['authors'].str.replace('\\'',' ')\n",
    "        md['authors'] = md['authors'].str.replace(',',' ')\n",
    "        \n",
    "        #print(md.head())\n",
    "\n",
    "        md['authors'] = md['authors'].apply(lambda x: [x,x])\n",
    "        md['year'] = md['year'].apply(lambda x: [x])\n",
    "        md['year'] = md['year'].apply(lambda x: [x])\n",
    "        #print(md['authors'])\n",
    "\n",
    "#         md['year']=md['year'].str.split(';')\n",
    "        #print(md['Genres'])\n",
    "    \n",
    "        \n",
    "#         print(md['authors'])\n",
    "#         print(md['year'])\n",
    "\n",
    "        md['soup'] = md['authors'] + md['year']\n",
    "#         print(md['soup'])\n",
    "\n",
    "        md['soup'] = md['soup'].str.join(' ')\n",
    "\n",
    "        #md['soup'].fillna({})\n",
    "        #print(md['soup'])\n",
    "\n",
    "        count = CountVectorizer(analyzer='word',ngram_range=(1,1),min_df=0, stop_words='english')\n",
    "        count_matrix = count.fit_transform(md['soup'].values.astype('U'))\n",
    "        print (count_matrix.shape)\n",
    "        #print np.array(count.get_feature_names())\n",
    "        #print(count_matrix.shape)\n",
    "\n",
    "\n",
    "        cosine_sim = cosine_similarity(count_matrix, count_matrix)\n",
    "\n",
    "        def build_user_profiles():\n",
    "            user_profiles=np.zeros((278858 ,1000))\n",
    "\t\t#taking only the first 100000 ratings to build user_profile\n",
    "            for i in range(0,45000):\n",
    "#                 print(i)\n",
    "                u=ratings.iloc[i]['user_id']\n",
    "                b=ratings.iloc[i]['book_id']\n",
    "                b2=self.md.index[self.md['book_id'] == b].tolist()[0]\n",
    "\t\t\n",
    "                user_profiles[u][b2-1]=ratings.iloc[i]['rating']\n",
    "                \n",
    "            return user_profiles\n",
    "\n",
    "        user_profiles=build_user_profiles()\n",
    "        print('profiles done')\n",
    "\n",
    "        def _get_similar_items_to_user_profile(person_id):\n",
    "            #Computes the cosine similarity between the user profile and all item profiles\n",
    "\n",
    "            user_ratings = np.empty((1000,1))\n",
    "            cnt=0\n",
    "            for i in range(0,999):\n",
    "                book_sim=cosine_sim[i]\n",
    "                user_sim=user_profiles[person_id]\n",
    "                user_ratings[i]=(book_sim.dot(user_sim))/sum(cosine_sim[i])\n",
    "            maxval = max(user_ratings)\n",
    "            print(maxval)\n",
    "\n",
    "            for i in range(0,999):\n",
    "                user_ratings[i]=((user_ratings[i]*10.0)/(maxval))\n",
    "\n",
    "                if(user_ratings[i]>3):\n",
    "\n",
    "                    cnt+=1\n",
    "\n",
    "            return user_ratings\n",
    "\n",
    "        content_ratings = _get_similar_items_to_user_profile(user_id)\n",
    "\n",
    "\n",
    "\n",
    "        num = md[['book_id']]\n",
    "        num1 = pd.DataFrame(data=content_ratings[0:,0:])\n",
    "        frames = [num, num1]\n",
    "\n",
    "\n",
    "        content_rating = pd.concat(frames, axis =1,join_axes=[num.index])\n",
    "        content_rating.columns=['book_id', 'content_rating']\n",
    "        #print(content_rating.shape)\n",
    "        #print(content_rating)\n",
    "\n",
    "        return(content_rating)\n",
    "\n",
    "    \n",
    "    def final_hybrid(self,md, popularity_rating , collaborative_rating, content_rating, user_id):\n",
    "\n",
    "        hyb = md[['book_id']]\n",
    "        title = md[['book_id','title', 'year']]\n",
    "\n",
    "        hyb = hyb.merge(title,on = 'book_id')\n",
    "        hyb = hyb.merge(self.collaborative_rating,on = 'book_id')\n",
    "        hyb = hyb.merge(self.popularity_rating, on='book_id')\n",
    "        hyb = hyb.merge(self.content_rating, on='book_id')\n",
    "\n",
    "        def weighted_rating(x):\n",
    "            v = x['rating']\n",
    "            R = x['popularity_rating']\n",
    "            c = x['content_rating']\n",
    "            return 0.4*v + 0.2*R + 0.4 * c\n",
    "\n",
    "\n",
    "        hyb['hyb_rating'] = hyb.apply(weighted_rating, axis=1)\n",
    "        hyb = hyb.sort_values('hyb_rating', ascending=False).head(999)\n",
    "        hyb.columns = ['Book ID' , 'Title', 'year', 'Collaborative Rating', 'Popularity Rating' , 'Content Rating', 'Hybrid Rating']\n",
    "        self.res=hyb\n",
    "        print(len(hyb['Hybrid Rating']))\n",
    "        print(hyb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------Results for276796-------------------\n",
      "       user_id     book_id  rating\n",
      "0       276746  0449006522       0\n",
      "1       276746  055356451X       0\n",
      "2       276755  0451166892       5\n",
      "3       276796  0330332775       5\n",
      "4       276847  0446364193       0\n",
      "...        ...         ...     ...\n",
      "44995   247055  0446612545       0\n",
      "44996   247055  051513290X       0\n",
      "44997   247055  0553278746       0\n",
      "44998   247055  0553576925       0\n",
      "44999   247055  0671004573       0\n",
      "\n",
      "[45000 rows x 3 columns]\n",
      "   user_id     book_id  rating\n",
      "3   276796  0330332775       5\n",
      "STARTING POPULARITY\n",
      "(1000, 6)\n",
      "(1000, 2)\n",
      "STARTING CONTENT\n",
      "(1000, 870)\n",
      "profiles done\n",
      "[0.34045244]\n",
      "STARTING COLABORATIVE\n",
      "STARTING HYBRID\n",
      "999\n",
      "        Book ID                                              Title    year  \\\n",
      "491  0671002481                  The First Wives Club Movie Tie In  [1996]   \n",
      "165  0451206673                                           Pen Pals  [2002]   \n",
      "303  0375719180            The Miracle Life of Edgar Mint: A Novel  [2002]   \n",
      "187  3257233051  Veronika Deschliesst Zu Sterben / Vernika Deci...  [2002]   \n",
      "408  0316666343                          The Lovely Bones: A Novel  [2002]   \n",
      "..          ...                                                ...     ...   \n",
      "975  0440224829                                         Granny Dan  [2000]   \n",
      "565  0385721420                                        Three Junes  [2003]   \n",
      "559  0671673688                         While My Pretty One Sleeps  [1990]   \n",
      "26   0971880107                                        Wild Animus  [2004]   \n",
      "971  0440130913                                         Golden Cup  [1987]   \n",
      "\n",
      "     Collaborative Rating  Popularity Rating  Content Rating  Hybrid Rating  \n",
      "491              2.561659           2.943613       10.000000       5.613386  \n",
      "165              4.917951           2.943586        6.400571       5.116126  \n",
      "303              5.000000           2.943586        1.326358       3.119261  \n",
      "187              4.853165           2.943569        1.326358       3.060523  \n",
      "408              4.874474           2.943569        1.280114       3.050549  \n",
      "..                    ...                ...             ...            ...  \n",
      "975              1.674228           2.943604        0.000000       1.258412  \n",
      "565              1.598833           2.943610        0.000000       1.228255  \n",
      "559              1.566711           2.943613        0.000000       1.215407  \n",
      "26               1.215401           2.943586        0.000000       1.074877  \n",
      "971              1.000000           2.943578        0.000000       0.988716  \n",
      "\n",
      "[999 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "ratings = pd.read_csv('dataset/processed/FinalRatings.csv')[0:45000]\n",
    "userId=276796\n",
    "print('\\n----------------Results for'+str(userId)+'-------------------')\n",
    "h = hybrid(userId,ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>year</th>\n",
       "      <th>Collaborative Rating</th>\n",
       "      <th>Popularity Rating</th>\n",
       "      <th>Content Rating</th>\n",
       "      <th>Hybrid Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>491</td>\n",
       "      <td>0671002481</td>\n",
       "      <td>The First Wives Club Movie Tie In</td>\n",
       "      <td>[1996]</td>\n",
       "      <td>2.561659</td>\n",
       "      <td>2.943613</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.613386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>0451206673</td>\n",
       "      <td>Pen Pals</td>\n",
       "      <td>[2002]</td>\n",
       "      <td>4.917951</td>\n",
       "      <td>2.943586</td>\n",
       "      <td>6.400571</td>\n",
       "      <td>5.116126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>303</td>\n",
       "      <td>0375719180</td>\n",
       "      <td>The Miracle Life of Edgar Mint: A Novel</td>\n",
       "      <td>[2002]</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.943586</td>\n",
       "      <td>1.326358</td>\n",
       "      <td>3.119261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>187</td>\n",
       "      <td>3257233051</td>\n",
       "      <td>Veronika Deschliesst Zu Sterben / Vernika Deci...</td>\n",
       "      <td>[2002]</td>\n",
       "      <td>4.853165</td>\n",
       "      <td>2.943569</td>\n",
       "      <td>1.326358</td>\n",
       "      <td>3.060523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>408</td>\n",
       "      <td>0316666343</td>\n",
       "      <td>The Lovely Bones: A Novel</td>\n",
       "      <td>[2002]</td>\n",
       "      <td>4.874474</td>\n",
       "      <td>2.943569</td>\n",
       "      <td>1.280114</td>\n",
       "      <td>3.050549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205</td>\n",
       "      <td>0316693006</td>\n",
       "      <td>Four Blind Mice</td>\n",
       "      <td>[2002]</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.943604</td>\n",
       "      <td>1.090083</td>\n",
       "      <td>3.024754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246</td>\n",
       "      <td>0151008116</td>\n",
       "      <td>Life of Pi</td>\n",
       "      <td>[2002]</td>\n",
       "      <td>4.700600</td>\n",
       "      <td>2.943586</td>\n",
       "      <td>1.280114</td>\n",
       "      <td>2.981003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>487</td>\n",
       "      <td>0805063897</td>\n",
       "      <td>Nickel and Dimed: On (Not) Getting By in America</td>\n",
       "      <td>[2002]</td>\n",
       "      <td>4.532518</td>\n",
       "      <td>2.943584</td>\n",
       "      <td>1.326358</td>\n",
       "      <td>2.932267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>479</td>\n",
       "      <td>0375726403</td>\n",
       "      <td>Empire Falls</td>\n",
       "      <td>[2002]</td>\n",
       "      <td>4.494567</td>\n",
       "      <td>2.943611</td>\n",
       "      <td>1.326358</td>\n",
       "      <td>2.917092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>156971620X</td>\n",
       "      <td>Harlequin Valentine</td>\n",
       "      <td>[2002]</td>\n",
       "      <td>4.463940</td>\n",
       "      <td>2.943586</td>\n",
       "      <td>1.196669</td>\n",
       "      <td>2.852961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>3404921038</td>\n",
       "      <td>Wie Barney es sieht.</td>\n",
       "      <td>[2002]</td>\n",
       "      <td>4.043118</td>\n",
       "      <td>2.943610</td>\n",
       "      <td>1.326358</td>\n",
       "      <td>2.736512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>299</td>\n",
       "      <td>1563898586</td>\n",
       "      <td>The League of Extraordinary Gentlemen, Vol. 1</td>\n",
       "      <td>[2002]</td>\n",
       "      <td>3.929379</td>\n",
       "      <td>2.943586</td>\n",
       "      <td>1.280114</td>\n",
       "      <td>2.672515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0449005615</td>\n",
       "      <td>Seabiscuit: An American Legend</td>\n",
       "      <td>[2002]</td>\n",
       "      <td>3.920438</td>\n",
       "      <td>2.943578</td>\n",
       "      <td>1.280114</td>\n",
       "      <td>2.668937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>263</td>\n",
       "      <td>0064472264</td>\n",
       "      <td>On the Bright Side, I'm Now the Girlfriend of ...</td>\n",
       "      <td>[2002]</td>\n",
       "      <td>3.835913</td>\n",
       "      <td>2.943586</td>\n",
       "      <td>1.326358</td>\n",
       "      <td>2.653626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>348</td>\n",
       "      <td>0771076002</td>\n",
       "      <td>Remembering Peter Gzowski : A Book of Tributes</td>\n",
       "      <td>[2002]</td>\n",
       "      <td>3.794934</td>\n",
       "      <td>2.943586</td>\n",
       "      <td>1.326358</td>\n",
       "      <td>2.637234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>227</td>\n",
       "      <td>0449006522</td>\n",
       "      <td>Manhattan Hunt Club</td>\n",
       "      <td>[2002]</td>\n",
       "      <td>3.720240</td>\n",
       "      <td>2.943610</td>\n",
       "      <td>1.326358</td>\n",
       "      <td>2.607361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177</td>\n",
       "      <td>3257203659</td>\n",
       "      <td>Der illustrierte Mann. ErzÃ?Â¤hlungen.</td>\n",
       "      <td>[2002]</td>\n",
       "      <td>4.112849</td>\n",
       "      <td>2.943595</td>\n",
       "      <td>0.925259</td>\n",
       "      <td>2.603962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>338</td>\n",
       "      <td>1573228737</td>\n",
       "      <td>Affinity</td>\n",
       "      <td>[2002]</td>\n",
       "      <td>3.704714</td>\n",
       "      <td>2.943586</td>\n",
       "      <td>1.326358</td>\n",
       "      <td>2.601146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>8445071408</td>\n",
       "      <td>El Senor De Los Anillos: LA Comunidad Del Anil...</td>\n",
       "      <td>[2001]</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.943616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.588723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>811</td>\n",
       "      <td>0743222229</td>\n",
       "      <td>George W. Bushisms : The Slate Book of The Acc...</td>\n",
       "      <td>[2001]</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.943616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.588723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Book ID                                              Title    year  \\\n",
       "491  0671002481                  The First Wives Club Movie Tie In  [1996]   \n",
       "165  0451206673                                           Pen Pals  [2002]   \n",
       "303  0375719180            The Miracle Life of Edgar Mint: A Novel  [2002]   \n",
       "187  3257233051  Veronika Deschliesst Zu Sterben / Vernika Deci...  [2002]   \n",
       "408  0316666343                          The Lovely Bones: A Novel  [2002]   \n",
       "205  0316693006                                    Four Blind Mice  [2002]   \n",
       "246  0151008116                                         Life of Pi  [2002]   \n",
       "487  0805063897   Nickel and Dimed: On (Not) Getting By in America  [2002]   \n",
       "479  0375726403                                       Empire Falls  [2002]   \n",
       "300  156971620X                                Harlequin Valentine  [2002]   \n",
       "32   3404921038                               Wie Barney es sieht.  [2002]   \n",
       "299  1563898586      The League of Extraordinary Gentlemen, Vol. 1  [2002]   \n",
       "38   0449005615                     Seabiscuit: An American Legend  [2002]   \n",
       "263  0064472264  On the Bright Side, I'm Now the Girlfriend of ...  [2002]   \n",
       "348  0771076002     Remembering Peter Gzowski : A Book of Tributes  [2002]   \n",
       "227  0449006522                                Manhattan Hunt Club  [2002]   \n",
       "177  3257203659             Der illustrierte Mann. ErzÃ?Â¤hlungen.  [2002]   \n",
       "338  1573228737                                           Affinity  [2002]   \n",
       "91   8445071408  El Senor De Los Anillos: LA Comunidad Del Anil...  [2001]   \n",
       "811  0743222229  George W. Bushisms : The Slate Book of The Acc...  [2001]   \n",
       "\n",
       "     Collaborative Rating  Popularity Rating  Content Rating  Hybrid Rating  \n",
       "491              2.561659           2.943613       10.000000       5.613386  \n",
       "165              4.917951           2.943586        6.400571       5.116126  \n",
       "303              5.000000           2.943586        1.326358       3.119261  \n",
       "187              4.853165           2.943569        1.326358       3.060523  \n",
       "408              4.874474           2.943569        1.280114       3.050549  \n",
       "205              5.000000           2.943604        1.090083       3.024754  \n",
       "246              4.700600           2.943586        1.280114       2.981003  \n",
       "487              4.532518           2.943584        1.326358       2.932267  \n",
       "479              4.494567           2.943611        1.326358       2.917092  \n",
       "300              4.463940           2.943586        1.196669       2.852961  \n",
       "32               4.043118           2.943610        1.326358       2.736512  \n",
       "299              3.929379           2.943586        1.280114       2.672515  \n",
       "38               3.920438           2.943578        1.280114       2.668937  \n",
       "263              3.835913           2.943586        1.326358       2.653626  \n",
       "348              3.794934           2.943586        1.326358       2.637234  \n",
       "227              3.720240           2.943610        1.326358       2.607361  \n",
       "177              4.112849           2.943595        0.925259       2.603962  \n",
       "338              3.704714           2.943586        1.326358       2.601146  \n",
       "91               5.000000           2.943616        0.000000       2.588723  \n",
       "811              5.000000           2.943616        0.000000       2.588723  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.res.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
